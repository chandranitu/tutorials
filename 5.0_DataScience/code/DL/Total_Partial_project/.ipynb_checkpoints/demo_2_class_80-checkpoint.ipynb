{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from IPython.display import Image, display, clear_output\n",
    "from collections import Counter\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns \n",
    "#%matplotlib inline\n",
    "\n",
    "import json\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_vgg16(crop=True, weights_path=''):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(3, 3), input_shape=(img_width, img_height,3),activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "  \n",
    "    model.add(Conv2D(64,(3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    # assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\")'\n",
    "    \n",
    "    if weights_path:\n",
    "    # note: this chops off the last layers of VGG16 \n",
    "    \n",
    "        f = h5py.File(weights_path)\n",
    "        for k in range(f.attrs['nb_layers']):\n",
    "            if k >= len(model.layers): \n",
    "            # we don't look at the last (fully-connected) layers in the savefile\n",
    "                break\n",
    "            g = f['layer_{}'.format(k)]\n",
    "            weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "            model.layers[k].set_weights(weights)\n",
    "            f.close()\n",
    "            print('VGG16 Model with partial weights loaded.')\n",
    "    else:\n",
    "        print('VGG16 Model with no weights Loaded.')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finetune_binary_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(100, 100,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    # compile the model with a SGD/momentum optimizer \n",
    "    # and a very slow learning rate\n",
    "    epochs = 150\n",
    "    lrate = 0.0001\n",
    "    decay = lrate/epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer = 'rmsprop', # reduced learning rate by 1/10\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # prepare data augmentation configuration\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       shear_range=0.2,\n",
    "                                       zoom_range=0.2,\n",
    "                                       horizontal_flip=True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator= train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                     target_size=(img_height, img_width),\n",
    "                                                     batch_size=8,\n",
    "                                                     class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                           target_size=(img_height, img_width),\n",
    "                                                           batch_size=8,\n",
    "                                                           class_mode='binary')\n",
    "    \n",
    "    \n",
    "    checkpoint = ModelCheckpoint(fine_tuned_model_path, monitor='val_acc', \n",
    "                                 verbose=1, save_best_only=True, \n",
    "                                 save_weights_only=False, mode='auto')\n",
    "    # fine-tune the model\n",
    "    fit = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=nb_train_samples // batch_size,\n",
    "                              epochs=nb_epoch,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=nb_validation_samples // batch_size,\n",
    "                              verbose=1)\n",
    "    \n",
    "    return model, fit.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to the model weights file\n",
    "location = 'C:\\\\Users\\\\pankaj.prabhakar\\\\Desktop\\\\defect_detection\\\\data2a'\n",
    "top_model_weights_path=location+'\\\\top_model_weights.h5' # will be saved into when we create our model\n",
    "# model_path = location + '/initial_data2_model.h5'\n",
    "fine_tuned_model_path = location+'\\\\ft_model.h5'\n",
    "\n",
    "# dimensions of our images\n",
    "img_width, img_height = 100, 100\n",
    "\n",
    "train_data_dir = location+'\\\\training'\n",
    "validation_data_dir = location+'\\\\validation'\n",
    "\n",
    "train_samples = [len(os.listdir(train_data_dir+'\\\\'+i)) for i in sorted(os.listdir(train_data_dir))]\n",
    "nb_train_samples = sum(train_samples)\n",
    "validation_samples = [len(os.listdir(validation_data_dir+'\\\\'+i)) for i in sorted(os.listdir(validation_data_dir))]\n",
    "nb_validation_samples = sum(validation_samples)\n",
    "batch_size=8\n",
    "nb_epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 707 images belonging to 2 classes.\n",
      "Found 123 images belonging to 2 classes.\n",
      "Epoch 1/200\n",
      "88/88 [==============================] - 10s - loss: 0.7087 - acc: 0.5938 - val_loss: 0.6755 - val_acc: 0.5833\n",
      "Epoch 2/200\n",
      "88/88 [==============================] - 9s - loss: 0.6838 - acc: 0.5980 - val_loss: 0.6701 - val_acc: 0.6000\n",
      "Epoch 3/200\n",
      "88/88 [==============================] - 10s - loss: 0.6809 - acc: 0.5951 - val_loss: 0.6784 - val_acc: 0.5652\n",
      "Epoch 4/200\n",
      "88/88 [==============================] - 11s - loss: 0.6761 - acc: 0.5924 - val_loss: 0.6677 - val_acc: 0.5739\n",
      "Epoch 5/200\n",
      "88/88 [==============================] - 11s - loss: 0.6733 - acc: 0.5942 - val_loss: 0.6647 - val_acc: 0.6261\n",
      "Epoch 6/200\n",
      "88/88 [==============================] - 11s - loss: 0.6772 - acc: 0.5890 - val_loss: 0.6586 - val_acc: 0.5826\n",
      "Epoch 7/200\n",
      "88/88 [==============================] - 11s - loss: 0.6684 - acc: 0.6051 - val_loss: 0.6574 - val_acc: 0.5826\n",
      "Epoch 8/200\n",
      "88/88 [==============================] - 10s - loss: 0.6639 - acc: 0.5782 - val_loss: 0.6325 - val_acc: 0.6435\n",
      "Epoch 9/200\n",
      "88/88 [==============================] - 11s - loss: 0.6732 - acc: 0.6217 - val_loss: 0.6542 - val_acc: 0.6000\n",
      "Epoch 10/200\n",
      "88/88 [==============================] - 11s - loss: 0.6610 - acc: 0.6264 - val_loss: 0.6308 - val_acc: 0.6261\n",
      "Epoch 11/200\n",
      "88/88 [==============================] - 11s - loss: 0.6570 - acc: 0.6193 - val_loss: 0.6438 - val_acc: 0.6522\n",
      "Epoch 12/200\n",
      "88/88 [==============================] - 11s - loss: 0.6346 - acc: 0.6411 - val_loss: 0.6662 - val_acc: 0.7043\n",
      "Epoch 13/200\n",
      "88/88 [==============================] - 11s - loss: 0.6364 - acc: 0.6647 - val_loss: 0.6517 - val_acc: 0.6348\n",
      "Epoch 14/200\n",
      "88/88 [==============================] - 11s - loss: 0.6438 - acc: 0.6383 - val_loss: 0.6322 - val_acc: 0.6522\n",
      "Epoch 15/200\n",
      "88/88 [==============================] - 11s - loss: 0.6079 - acc: 0.6601 - val_loss: 0.6520 - val_acc: 0.7043\n",
      "Epoch 16/200\n",
      "88/88 [==============================] - 11s - loss: 0.6202 - acc: 0.6681 - val_loss: 0.6389 - val_acc: 0.6696\n",
      "Epoch 17/200\n",
      "88/88 [==============================] - 11s - loss: 0.6180 - acc: 0.6780 - val_loss: 0.6123 - val_acc: 0.6261\n",
      "Epoch 18/200\n",
      "88/88 [==============================] - 11s - loss: 0.5870 - acc: 0.6970 - val_loss: 0.6517 - val_acc: 0.6250\n",
      "Epoch 19/200\n",
      "88/88 [==============================] - 11s - loss: 0.5428 - acc: 0.7604 - val_loss: 0.7005 - val_acc: 0.6609\n",
      "Epoch 20/200\n",
      "88/88 [==============================] - 10s - loss: 0.5576 - acc: 0.7349 - val_loss: 0.6767 - val_acc: 0.7391\n",
      "Epoch 21/200\n",
      "88/88 [==============================] - 11s - loss: 0.5494 - acc: 0.7443 - val_loss: 0.6256 - val_acc: 0.6609\n",
      "Epoch 22/200\n",
      "88/88 [==============================] - 10s - loss: 0.5256 - acc: 0.7542 - val_loss: 0.5756 - val_acc: 0.7478\n",
      "Epoch 23/200\n",
      "88/88 [==============================] - 11s - loss: 0.5259 - acc: 0.7590 - val_loss: 0.5862 - val_acc: 0.7913\n",
      "Epoch 24/200\n",
      "88/88 [==============================] - 11s - loss: 0.5607 - acc: 0.7505 - val_loss: 0.5451 - val_acc: 0.7652\n",
      "Epoch 25/200\n",
      "88/88 [==============================] - 11s - loss: 0.5201 - acc: 0.7628 - val_loss: 0.6772 - val_acc: 0.6609\n",
      "Epoch 26/200\n",
      "88/88 [==============================] - 11s - loss: 0.5447 - acc: 0.7434 - val_loss: 0.5602 - val_acc: 0.7652\n",
      "Epoch 27/200\n",
      "88/88 [==============================] - 11s - loss: 0.5274 - acc: 0.7656 - val_loss: 0.6051 - val_acc: 0.7217\n",
      "Epoch 28/200\n",
      "88/88 [==============================] - 11s - loss: 0.5375 - acc: 0.7604 - val_loss: 0.6300 - val_acc: 0.7652\n",
      "Epoch 29/200\n",
      "88/88 [==============================] - 11s - loss: 0.5345 - acc: 0.7623 - val_loss: 0.9405 - val_acc: 0.6174\n",
      "Epoch 30/200\n",
      "88/88 [==============================] - 11s - loss: 0.4894 - acc: 0.7684 - val_loss: 0.6552 - val_acc: 0.6957\n",
      "Epoch 31/200\n",
      "88/88 [==============================] - 11s - loss: 0.5413 - acc: 0.7604 - val_loss: 0.6364 - val_acc: 0.7130\n",
      "Epoch 32/200\n",
      "88/88 [==============================] - 11s - loss: 0.4956 - acc: 0.7832 - val_loss: 0.7033 - val_acc: 0.7304\n",
      "Epoch 33/200\n",
      "88/88 [==============================] - 11s - loss: 0.5279 - acc: 0.7576 - val_loss: 0.7543 - val_acc: 0.7043\n",
      "Epoch 34/200\n",
      "88/88 [==============================] - 11s - loss: 0.5447 - acc: 0.7481 - val_loss: 0.5746 - val_acc: 0.7739\n",
      "Epoch 35/200\n",
      "88/88 [==============================] - 11s - loss: 0.5468 - acc: 0.7661 - val_loss: 0.5739 - val_acc: 0.7130\n",
      "Epoch 36/200\n",
      "88/88 [==============================] - 11s - loss: 0.5271 - acc: 0.7642 - val_loss: 0.5650 - val_acc: 0.7565\n",
      "Epoch 37/200\n",
      "88/88 [==============================] - 11s - loss: 0.5257 - acc: 0.7661 - val_loss: 0.6991 - val_acc: 0.6870\n",
      "Epoch 38/200\n",
      "88/88 [==============================] - 11s - loss: 0.5089 - acc: 0.7718 - val_loss: 0.7800 - val_acc: 0.7130\n",
      "Epoch 39/200\n",
      "88/88 [==============================] - 11s - loss: 0.5164 - acc: 0.7803 - val_loss: 0.7459 - val_acc: 0.6957\n",
      "Epoch 40/200\n",
      "88/88 [==============================] - 11s - loss: 0.4713 - acc: 0.7846 - val_loss: 0.8547 - val_acc: 0.6522\n",
      "Epoch 41/200\n",
      "88/88 [==============================] - 11s - loss: 0.5639 - acc: 0.7552 - val_loss: 0.8851 - val_acc: 0.7130\n",
      "Epoch 42/200\n",
      "88/88 [==============================] - 11s - loss: 0.4716 - acc: 0.7812 - val_loss: 0.6878 - val_acc: 0.7043\n",
      "Epoch 43/200\n",
      "88/88 [==============================] - 11s - loss: 0.4951 - acc: 0.7642 - val_loss: 0.7069 - val_acc: 0.6870\n",
      "Epoch 44/200\n",
      "88/88 [==============================] - 12s - loss: 0.5161 - acc: 0.7571 - val_loss: 0.6968 - val_acc: 0.6870\n",
      "Epoch 45/200\n",
      "88/88 [==============================] - 13s - loss: 0.4881 - acc: 0.7737 - val_loss: 0.9695 - val_acc: 0.6957\n",
      "Epoch 46/200\n",
      "88/88 [==============================] - 13s - loss: 0.5406 - acc: 0.7623 - val_loss: 0.6662 - val_acc: 0.7583\n",
      "Epoch 47/200\n",
      "88/88 [==============================] - 12s - loss: 0.5177 - acc: 0.7888 - val_loss: 0.7795 - val_acc: 0.7478\n",
      "Epoch 48/200\n",
      "88/88 [==============================] - 12s - loss: 0.5295 - acc: 0.7841 - val_loss: 0.7762 - val_acc: 0.6783\n",
      "Epoch 49/200\n",
      "88/88 [==============================] - 12s - loss: 0.4956 - acc: 0.7926 - val_loss: 0.7731 - val_acc: 0.7083\n",
      "Epoch 50/200\n",
      "88/88 [==============================] - 12s - loss: 0.5022 - acc: 0.7684 - val_loss: 0.6443 - val_acc: 0.7478\n",
      "Epoch 51/200\n",
      "88/88 [==============================] - 12s - loss: 0.6338 - acc: 0.7699 - val_loss: 0.6432 - val_acc: 0.7652\n",
      "Epoch 52/200\n",
      "88/88 [==============================] - 11s - loss: 0.5250 - acc: 0.7822 - val_loss: 0.7092 - val_acc: 0.7391\n",
      "Epoch 53/200\n",
      "88/88 [==============================] - 12s - loss: 0.5514 - acc: 0.7699 - val_loss: 0.7197 - val_acc: 0.6957\n",
      "Epoch 54/200\n",
      "88/88 [==============================] - 12s - loss: 0.5552 - acc: 0.7718 - val_loss: 0.6531 - val_acc: 0.7478\n",
      "Epoch 55/200\n",
      "88/88 [==============================] - 11s - loss: 0.5591 - acc: 0.7709 - val_loss: 0.6259 - val_acc: 0.7652\n",
      "Epoch 56/200\n",
      "88/88 [==============================] - 11s - loss: 0.5368 - acc: 0.7604 - val_loss: 0.7557 - val_acc: 0.7565\n",
      "Epoch 57/200\n",
      "88/88 [==============================] - 11s - loss: 0.5549 - acc: 0.7684 - val_loss: 0.6198 - val_acc: 0.7826\n",
      "Epoch 58/200\n",
      "88/88 [==============================] - 11s - loss: 0.5482 - acc: 0.7533 - val_loss: 0.5081 - val_acc: 0.7739\n",
      "Epoch 59/200\n",
      "88/88 [==============================] - 11s - loss: 0.5242 - acc: 0.7661 - val_loss: 0.8325 - val_acc: 0.7043\n",
      "Epoch 60/200\n",
      "88/88 [==============================] - 11s - loss: 0.4908 - acc: 0.7766 - val_loss: 0.8375 - val_acc: 0.7652\n",
      "Epoch 61/200\n",
      "88/88 [==============================] - 11s - loss: 0.5028 - acc: 0.7803 - val_loss: 0.6148 - val_acc: 0.7478\n",
      "Epoch 62/200\n",
      "88/88 [==============================] - 11s - loss: 0.5555 - acc: 0.7415 - val_loss: 0.5414 - val_acc: 0.7565\n",
      "Epoch 63/200\n",
      "88/88 [==============================] - 11s - loss: 0.5284 - acc: 0.7670 - val_loss: 0.6410 - val_acc: 0.7304\n",
      "Epoch 64/200\n",
      "88/88 [==============================] - 11s - loss: 0.5512 - acc: 0.7533 - val_loss: 0.6404 - val_acc: 0.7304\n",
      "Epoch 65/200\n",
      "88/88 [==============================] - 11s - loss: 0.5840 - acc: 0.7386 - val_loss: 0.8227 - val_acc: 0.7391\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 11s - loss: 0.5148 - acc: 0.7704 - val_loss: 1.1695 - val_acc: 0.6696\n",
      "Epoch 67/200\n",
      "88/88 [==============================] - 11s - loss: 0.5560 - acc: 0.7505 - val_loss: 0.6512 - val_acc: 0.7652\n",
      "Epoch 68/200\n",
      "88/88 [==============================] - 11s - loss: 0.5793 - acc: 0.7590 - val_loss: 0.6695 - val_acc: 0.7130\n",
      "Epoch 69/200\n",
      "88/88 [==============================] - 11s - loss: 0.5929 - acc: 0.7656 - val_loss: 0.6278 - val_acc: 0.7739\n",
      "Epoch 70/200\n",
      "88/88 [==============================] - 11s - loss: 0.5771 - acc: 0.7562 - val_loss: 3.6737 - val_acc: 0.6696\n",
      "Epoch 71/200\n",
      "88/88 [==============================] - 11s - loss: 0.7272 - acc: 0.7439 - val_loss: 0.5252 - val_acc: 0.7478\n",
      "Epoch 72/200\n",
      "88/88 [==============================] - 10s - loss: 0.5958 - acc: 0.7382 - val_loss: 0.8576 - val_acc: 0.6870\n",
      "Epoch 73/200\n",
      "88/88 [==============================] - 10s - loss: 0.6547 - acc: 0.7429 - val_loss: 0.6896 - val_acc: 0.7565\n",
      "Epoch 74/200\n",
      "88/88 [==============================] - 11s - loss: 0.5621 - acc: 0.7613 - val_loss: 0.6001 - val_acc: 0.7304\n",
      "Epoch 75/200\n",
      "88/88 [==============================] - 11s - loss: 0.6103 - acc: 0.7373 - val_loss: 0.5147 - val_acc: 0.7217\n",
      "Epoch 76/200\n",
      "88/88 [==============================] - 11s - loss: 0.5456 - acc: 0.7599 - val_loss: 0.6090 - val_acc: 0.7652\n",
      "Epoch 77/200\n",
      "88/88 [==============================] - 11s - loss: 0.5732 - acc: 0.7528 - val_loss: 0.8339 - val_acc: 0.7391\n",
      "Epoch 78/200\n",
      " 1/88 [..............................] - ETA: 10s - loss: 0.1806 - acc: 0.8750"
     ]
    }
   ],
   "source": [
    "finetune_binary_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
