{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from IPython.display import Image, display, clear_output\n",
    "from collections import Counter\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns \n",
    "#%matplotlib inline\n",
    "\n",
    "import json\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.constraints import maxnorm\n",
    "#sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the model weights file\n",
    "#location = 'C:\\\\Users\\\\pankaj.prabhakar\\\\Desktop\\\\defect_detection\\\\injury'\n",
    "#location = 'C:\\\\Users\\\\pankaj.prabhakar\\\\Desktop\\\\Total_Partial\\\\damage_non_damage'\n",
    "location = 'C:\\\\Users\\\\pankaj.prabhakar\\\\Desktop\\\\Total_Partial\\\\data'\n",
    "top_model_weights_path=location+'\\\\top_model_weights.h5' # will be saved into when we create our model\n",
    "# model_path = location + '/initial_data2_model.h5'\n",
    "fine_tuned_model_path = location+'\\\\damage-vs-nondamage.h5'\n",
    "\n",
    "# dimensions of our images\n",
    "img_width, img_height = 100, 100\n",
    "\n",
    "train_data_dir = location+'\\\\training'\n",
    "validation_data_dir = location+'\\\\validation'\n",
    "\n",
    "train_samples = [len(os.listdir(train_data_dir+'\\\\'+i)) for i in sorted(os.listdir(train_data_dir))]\n",
    "nb_train_samples = sum(train_samples)\n",
    "validation_samples = [len(os.listdir(validation_data_dir+'\\\\'+i)) for i in sorted(os.listdir(validation_data_dir))]\n",
    "nb_validation_samples = sum(validation_samples)\n",
    "batch_size=8\n",
    "nb_epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_path='C:\\\\Users\\\\pankaj.prabhakar\\\\Desktop\\\\defect_detection\\\\vgg16_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2028 images belonging to 2 classes.\n",
      "Found 460 images belonging to 2 classes.\n",
      "Epoch 1/300\n",
      " 94/253 [==========>...................] - ETA: 31s - loss: 0.7039 - acc: 0.5306"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pankaj.prabhakar\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:918: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/253 [============================>.] - ETA: 0s - loss: 0.6934 - acc: 0.5570Epoch 00000: val_acc improved from -inf to 0.49781, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 57s - loss: 0.6929 - acc: 0.5578 - val_loss: 0.6980 - val_acc: 0.4978\n",
      "Epoch 2/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.6767 - acc: 0.5774Epoch 00001: val_acc improved from 0.49781 to 0.55973, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 61s - loss: 0.6767 - acc: 0.5776 - val_loss: 0.6836 - val_acc: 0.5597\n",
      "Epoch 3/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.6606 - acc: 0.6126Epoch 00002: val_acc did not improve\n",
      "253/253 [==============================] - 62s - loss: 0.6600 - acc: 0.6136 - val_loss: 0.6802 - val_acc: 0.5531\n",
      "Epoch 4/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.6478 - acc: 0.6324Epoch 00003: val_acc improved from 0.55973 to 0.60177, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 59s - loss: 0.6473 - acc: 0.6329 - val_loss: 0.6631 - val_acc: 0.6018\n",
      "Epoch 5/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.6373 - acc: 0.6528Epoch 00004: val_acc did not improve\n",
      "253/253 [==============================] - 60s - loss: 0.6373 - acc: 0.6522 - val_loss: 0.6601 - val_acc: 0.5973\n",
      "Epoch 6/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.6256 - acc: 0.6597Epoch 00005: val_acc improved from 0.60177 to 0.62832, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 62s - loss: 0.6256 - acc: 0.6591 - val_loss: 0.6467 - val_acc: 0.6283\n",
      "Epoch 7/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.6127 - acc: 0.6776Epoch 00006: val_acc improved from 0.62832 to 0.65265, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 60s - loss: 0.6126 - acc: 0.6779 - val_loss: 0.6323 - val_acc: 0.6527\n",
      "Epoch 8/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.6026 - acc: 0.6830Epoch 00007: val_acc improved from 0.65265 to 0.66593, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 59s - loss: 0.6027 - acc: 0.6833 - val_loss: 0.6107 - val_acc: 0.6659\n",
      "Epoch 9/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.5969 - acc: 0.6845Epoch 00008: val_acc did not improve\n",
      "253/253 [==============================] - 62s - loss: 0.5972 - acc: 0.6848 - val_loss: 0.6216 - val_acc: 0.6549\n",
      "Epoch 10/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.5779 - acc: 0.7133Epoch 00009: val_acc improved from 0.66593 to 0.68584, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 59s - loss: 0.5782 - acc: 0.7124 - val_loss: 0.5858 - val_acc: 0.6858\n",
      "Epoch 11/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.5771 - acc: 0.7029Epoch 00010: val_acc improved from 0.68584 to 0.70133, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 59s - loss: 0.5773 - acc: 0.7026 - val_loss: 0.5740 - val_acc: 0.7013\n",
      "Epoch 12/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.5656 - acc: 0.7078Epoch 00011: val_acc improved from 0.70133 to 0.71460, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 59s - loss: 0.5656 - acc: 0.7080 - val_loss: 0.5630 - val_acc: 0.7146\n",
      "Epoch 13/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.5550 - acc: 0.7257Epoch 00012: val_acc did not improve\n",
      "253/253 [==============================] - 58s - loss: 0.5545 - acc: 0.7253 - val_loss: 0.5876 - val_acc: 0.6748\n",
      "Epoch 14/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.5504 - acc: 0.7272Epoch 00013: val_acc improved from 0.71460 to 0.73451, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 59s - loss: 0.5504 - acc: 0.7268 - val_loss: 0.5522 - val_acc: 0.7345\n",
      "Epoch 15/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.5420 - acc: 0.7277Epoch 00014: val_acc did not improve\n",
      "253/253 [==============================] - 59s - loss: 0.5409 - acc: 0.7288 - val_loss: 0.5283 - val_acc: 0.7301\n",
      "Epoch 16/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.5343 - acc: 0.7391Epoch 00015: val_acc improved from 0.73451 to 0.73894, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 60s - loss: 0.5343 - acc: 0.7391 - val_loss: 0.5372 - val_acc: 0.7389\n",
      "Epoch 17/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.5215 - acc: 0.7302Epoch 00016: val_acc improved from 0.73894 to 0.74336, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 59s - loss: 0.5218 - acc: 0.7302 - val_loss: 0.5280 - val_acc: 0.7434\n",
      "Epoch 18/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.5094 - acc: 0.7569Epoch 00017: val_acc improved from 0.74336 to 0.76327, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 60s - loss: 0.5083 - acc: 0.7579 - val_loss: 0.4805 - val_acc: 0.7633\n",
      "Epoch 19/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.5236 - acc: 0.7371Epoch 00018: val_acc did not improve\n",
      "253/253 [==============================] - 59s - loss: 0.5224 - acc: 0.7381 - val_loss: 0.5194 - val_acc: 0.7412\n",
      "Epoch 20/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4965 - acc: 0.7644Epoch 00019: val_acc improved from 0.76327 to 0.78540, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 59s - loss: 0.4959 - acc: 0.7643 - val_loss: 0.4901 - val_acc: 0.7854\n",
      "Epoch 21/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4837 - acc: 0.7684Epoch 00020: val_acc did not improve\n",
      "253/253 [==============================] - 59s - loss: 0.4850 - acc: 0.7683 - val_loss: 0.4810 - val_acc: 0.7500\n",
      "Epoch 22/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4939 - acc: 0.7574Epoch 00021: val_acc did not improve\n",
      "253/253 [==============================] - 60s - loss: 0.4931 - acc: 0.7579 - val_loss: 0.4915 - val_acc: 0.7500\n",
      "Epoch 23/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4735 - acc: 0.7688Epoch 00022: val_acc did not improve\n",
      "253/253 [==============================] - 60s - loss: 0.4733 - acc: 0.7688 - val_loss: 0.5045 - val_acc: 0.7544\n",
      "Epoch 24/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4617 - acc: 0.7941Epoch 00023: val_acc improved from 0.78540 to 0.78982, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 61s - loss: 0.4618 - acc: 0.7940 - val_loss: 0.4638 - val_acc: 0.7898\n",
      "Epoch 25/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4666 - acc: 0.7842Epoch 00024: val_acc improved from 0.78982 to 0.80973, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 59s - loss: 0.4679 - acc: 0.7826 - val_loss: 0.4523 - val_acc: 0.8097\n",
      "Epoch 26/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4501 - acc: 0.7927Epoch 00025: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253/253 [==============================] - 60s - loss: 0.4501 - acc: 0.7925 - val_loss: 0.4685 - val_acc: 0.7788\n",
      "Epoch 27/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4503 - acc: 0.7902Epoch 00026: val_acc did not improve\n",
      "253/253 [==============================] - 58s - loss: 0.4499 - acc: 0.7900 - val_loss: 0.4577 - val_acc: 0.7898\n",
      "Epoch 28/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4473 - acc: 0.7927Epoch 00027: val_acc did not improve\n",
      "253/253 [==============================] - 58s - loss: 0.4470 - acc: 0.7930 - val_loss: 0.4303 - val_acc: 0.8075\n",
      "Epoch 29/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4388 - acc: 0.7927Epoch 00028: val_acc did not improve\n",
      "253/253 [==============================] - 58s - loss: 0.4394 - acc: 0.7920 - val_loss: 0.4749 - val_acc: 0.7677\n",
      "Epoch 30/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4439 - acc: 0.7996Epoch 00029: val_acc did not improve\n",
      "253/253 [==============================] - 60s - loss: 0.4435 - acc: 0.7994 - val_loss: 0.4403 - val_acc: 0.8009\n",
      "Epoch 31/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4376 - acc: 0.7941Epoch 00030: val_acc did not improve\n",
      "253/253 [==============================] - 59s - loss: 0.4375 - acc: 0.7945 - val_loss: 0.4720 - val_acc: 0.7633\n",
      "Epoch 32/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4434 - acc: 0.7922Epoch 00031: val_acc improved from 0.80973 to 0.81637, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 63s - loss: 0.4440 - acc: 0.7915 - val_loss: 0.4357 - val_acc: 0.8164\n",
      "Epoch 33/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4195 - acc: 0.8115Epoch 00032: val_acc did not improve\n",
      "253/253 [==============================] - 64s - loss: 0.4198 - acc: 0.8108 - val_loss: 0.4633 - val_acc: 0.7898\n",
      "Epoch 34/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4329 - acc: 0.7956Epoch 00033: val_acc improved from 0.81637 to 0.83407, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 60s - loss: 0.4328 - acc: 0.7960 - val_loss: 0.3918 - val_acc: 0.8341\n",
      "Epoch 35/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4251 - acc: 0.8130Epoch 00034: val_acc did not improve\n",
      "253/253 [==============================] - 59s - loss: 0.4264 - acc: 0.8113 - val_loss: 0.4323 - val_acc: 0.8164\n",
      "Epoch 36/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4153 - acc: 0.8046Epoch 00035: val_acc improved from 0.83407 to 0.84513, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 60s - loss: 0.4155 - acc: 0.8039 - val_loss: 0.3942 - val_acc: 0.8451\n",
      "Epoch 37/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4288 - acc: 0.8105Epoch 00036: val_acc did not improve\n",
      "253/253 [==============================] - 59s - loss: 0.4282 - acc: 0.8108 - val_loss: 0.4543 - val_acc: 0.7677\n",
      "Epoch 38/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3994 - acc: 0.8180Epoch 00037: val_acc did not improve\n",
      "253/253 [==============================] - 59s - loss: 0.4004 - acc: 0.8177 - val_loss: 0.3886 - val_acc: 0.8208\n",
      "Epoch 39/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3946 - acc: 0.8289Epoch 00038: val_acc did not improve\n",
      "253/253 [==============================] - 61s - loss: 0.3936 - acc: 0.8295 - val_loss: 0.3857 - val_acc: 0.8274\n",
      "Epoch 40/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3990 - acc: 0.8199Epoch 00039: val_acc did not improve\n",
      "253/253 [==============================] - 59s - loss: 0.3985 - acc: 0.8202 - val_loss: 0.3878 - val_acc: 0.8230\n",
      "Epoch 41/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3960 - acc: 0.8160Epoch 00040: val_acc did not improve\n",
      "253/253 [==============================] - 59s - loss: 0.3956 - acc: 0.8162 - val_loss: 0.3829 - val_acc: 0.8164\n",
      "Epoch 42/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4032 - acc: 0.8140Epoch 00041: val_acc did not improve\n",
      "253/253 [==============================] - 60s - loss: 0.4045 - acc: 0.8132 - val_loss: 0.4350 - val_acc: 0.8097\n",
      "Epoch 43/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3690 - acc: 0.8368Epoch 00042: val_acc did not improve\n",
      "253/253 [==============================] - 61s - loss: 0.3709 - acc: 0.8365 - val_loss: 0.4041 - val_acc: 0.8142\n",
      "Epoch 44/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3628 - acc: 0.8423Epoch 00043: val_acc did not improve\n",
      "253/253 [==============================] - 64s - loss: 0.3628 - acc: 0.8419 - val_loss: 0.4006 - val_acc: 0.8296\n",
      "Epoch 45/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3807 - acc: 0.8239Epoch 00044: val_acc did not improve\n",
      "253/253 [==============================] - 63s - loss: 0.3814 - acc: 0.8236 - val_loss: 0.4047 - val_acc: 0.8075\n",
      "Epoch 46/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3919 - acc: 0.8269Epoch 00045: val_acc improved from 0.84513 to 0.85398, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 60s - loss: 0.3913 - acc: 0.8271 - val_loss: 0.3659 - val_acc: 0.8540\n",
      "Epoch 47/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3561 - acc: 0.8378Epoch 00046: val_acc did not improve\n",
      "253/253 [==============================] - 59s - loss: 0.3554 - acc: 0.8379 - val_loss: 0.3856 - val_acc: 0.8429\n",
      "Epoch 48/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3819 - acc: 0.8254Epoch 00047: val_acc improved from 0.85398 to 0.85841, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 61s - loss: 0.3810 - acc: 0.8261 - val_loss: 0.3616 - val_acc: 0.8584\n",
      "Epoch 49/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3592 - acc: 0.8408Epoch 00048: val_acc did not improve\n",
      "253/253 [==============================] - 61s - loss: 0.3598 - acc: 0.8404 - val_loss: 0.4160 - val_acc: 0.8429\n",
      "Epoch 50/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3698 - acc: 0.8299Epoch 00049: val_acc improved from 0.85841 to 0.86504, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 60s - loss: 0.3689 - acc: 0.8305 - val_loss: 0.3461 - val_acc: 0.8650\n",
      "Epoch 51/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3694 - acc: 0.8413Epoch 00050: val_acc did not improve\n",
      "253/253 [==============================] - 66s - loss: 0.3688 - acc: 0.8419 - val_loss: 0.3780 - val_acc: 0.8540\n",
      "Epoch 52/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3555 - acc: 0.8442Epoch 00051: val_acc did not improve\n",
      "253/253 [==============================] - 67s - loss: 0.3551 - acc: 0.8444 - val_loss: 0.3892 - val_acc: 0.8429\n",
      "Epoch 53/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3695 - acc: 0.8368Epoch 00052: val_acc did not improve\n",
      "253/253 [==============================] - 63s - loss: 0.3692 - acc: 0.8374 - val_loss: 0.3824 - val_acc: 0.8473\n",
      "Epoch 54/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3578 - acc: 0.8393Epoch 00053: val_acc did not improve\n",
      "253/253 [==============================] - 61s - loss: 0.3573 - acc: 0.8394 - val_loss: 0.3804 - val_acc: 0.8496\n",
      "Epoch 55/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3517 - acc: 0.8438Epoch 00054: val_acc did not improve\n",
      "253/253 [==============================] - 64s - loss: 0.3529 - acc: 0.8429 - val_loss: 0.3729 - val_acc: 0.8319\n",
      "Epoch 56/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3518 - acc: 0.8462Epoch 00055: val_acc did not improve\n",
      "253/253 [==============================] - 66s - loss: 0.3539 - acc: 0.8444 - val_loss: 0.4132 - val_acc: 0.8451\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/253 [============================>.] - ETA: 0s - loss: 0.3381 - acc: 0.8507Epoch 00056: val_acc did not improve\n",
      "253/253 [==============================] - 67s - loss: 0.3378 - acc: 0.8508 - val_loss: 0.3550 - val_acc: 0.8540\n",
      "Epoch 58/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3231 - acc: 0.8566Epoch 00057: val_acc improved from 0.86504 to 0.86947, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 65s - loss: 0.3225 - acc: 0.8572 - val_loss: 0.3501 - val_acc: 0.8695\n",
      "Epoch 59/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3286 - acc: 0.8586Epoch 00058: val_acc improved from 0.86947 to 0.87389, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 60s - loss: 0.3282 - acc: 0.8587 - val_loss: 0.3522 - val_acc: 0.8739\n",
      "Epoch 60/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3293 - acc: 0.8517Epoch 00059: val_acc did not improve\n",
      "253/253 [==============================] - 63s - loss: 0.3310 - acc: 0.8513 - val_loss: 0.3905 - val_acc: 0.8562\n",
      "Epoch 61/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3345 - acc: 0.8591Epoch 00060: val_acc did not improve\n",
      "253/253 [==============================] - 67s - loss: 0.3350 - acc: 0.8587 - val_loss: 0.3529 - val_acc: 0.8606\n",
      "Epoch 62/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3283 - acc: 0.8596Epoch 00061: val_acc did not improve\n",
      "253/253 [==============================] - 70s - loss: 0.3278 - acc: 0.8597 - val_loss: 0.3545 - val_acc: 0.8606\n",
      "Epoch 63/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3216 - acc: 0.8666Epoch 00062: val_acc did not improve\n",
      "253/253 [==============================] - 64s - loss: 0.3212 - acc: 0.8666 - val_loss: 0.3596 - val_acc: 0.8451\n",
      "Epoch 64/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3256 - acc: 0.8591Epoch 00063: val_acc did not improve\n",
      "253/253 [==============================] - 63s - loss: 0.3250 - acc: 0.8592 - val_loss: 0.3775 - val_acc: 0.8562\n",
      "Epoch 65/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3156 - acc: 0.8666Epoch 00064: val_acc did not improve\n",
      "253/253 [==============================] - 65s - loss: 0.3166 - acc: 0.8661 - val_loss: 0.3679 - val_acc: 0.8451\n",
      "Epoch 66/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3110 - acc: 0.8636Epoch 00065: val_acc did not improve\n",
      "253/253 [==============================] - 64s - loss: 0.3110 - acc: 0.8636 - val_loss: 0.3574 - val_acc: 0.8606\n",
      "Epoch 67/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3214 - acc: 0.8591Epoch 00066: val_acc improved from 0.87389 to 0.87832, saving model to C:\\Users\\pankaj.prabhakar\\Desktop\\Total_Partial\\damage_non_damage\\damage-vs-nondamage.h5\n",
      "253/253 [==============================] - 66s - loss: 0.3214 - acc: 0.8592 - val_loss: 0.3415 - val_acc: 0.8783\n",
      "Epoch 68/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.3048 - acc: 0.8705Epoch 00067: val_acc did not improve\n",
      "253/253 [==============================] - 61s - loss: 0.3047 - acc: 0.8706 - val_loss: 0.3348 - val_acc: 0.8606\n",
      "Epoch 69/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.2965 - acc: 0.8780Epoch 00068: val_acc did not improve\n",
      "253/253 [==============================] - 61s - loss: 0.2957 - acc: 0.8785 - val_loss: 0.3548 - val_acc: 0.8540\n",
      "Epoch 70/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.2932 - acc: 0.8735Epoch 00069: val_acc did not improve\n",
      "253/253 [==============================] - 60s - loss: 0.2925 - acc: 0.8740 - val_loss: 0.3227 - val_acc: 0.8650\n",
      "Epoch 71/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.2798 - acc: 0.8814Epoch 00070: val_acc did not improve\n",
      "253/253 [==============================] - 64s - loss: 0.2798 - acc: 0.8814 - val_loss: 0.3651 - val_acc: 0.8473\n",
      "Epoch 72/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.2970 - acc: 0.8720Epoch 00071: val_acc did not improve\n",
      "253/253 [==============================] - 63s - loss: 0.2968 - acc: 0.8715 - val_loss: 0.3599 - val_acc: 0.8451\n",
      "Epoch 73/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.2891 - acc: 0.8765Epoch 00072: val_acc did not improve\n",
      "253/253 [==============================] - 58s - loss: 0.2891 - acc: 0.8765 - val_loss: 0.3887 - val_acc: 0.8363\n",
      "Epoch 74/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.2720 - acc: 0.8760Epoch 00073: val_acc did not improve\n",
      "253/253 [==============================] - 62s - loss: 0.2716 - acc: 0.8760 - val_loss: 0.3426 - val_acc: 0.8673\n",
      "Epoch 75/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.2820 - acc: 0.8735Epoch 00074: val_acc did not improve\n",
      "253/253 [==============================] - 64s - loss: 0.2814 - acc: 0.8735 - val_loss: 0.3240 - val_acc: 0.8606\n",
      "Epoch 76/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.2824 - acc: 0.8814Epoch 00075: val_acc did not improve\n",
      "253/253 [==============================] - 62s - loss: 0.2828 - acc: 0.8809 - val_loss: 0.4166 - val_acc: 0.8230\n",
      "Epoch 77/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.2762 - acc: 0.8864Epoch 00076: val_acc did not improve\n",
      "253/253 [==============================] - 67s - loss: 0.2760 - acc: 0.8864 - val_loss: 0.3659 - val_acc: 0.8562\n",
      "Epoch 78/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.2685 - acc: 0.8839Epoch 00077: val_acc did not improve\n",
      "253/253 [==============================] - 69s - loss: 0.2682 - acc: 0.8844 - val_loss: 0.3591 - val_acc: 0.8473\n",
      "Epoch 79/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.2740 - acc: 0.8854Epoch 00078: val_acc did not improve\n",
      "253/253 [==============================] - 63s - loss: 0.2748 - acc: 0.8849 - val_loss: 0.3925 - val_acc: 0.8407\n",
      "Epoch 80/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.2720 - acc: 0.8834Epoch 00079: val_acc did not improve\n",
      "253/253 [==============================] - 58s - loss: 0.2716 - acc: 0.8839 - val_loss: 0.3649 - val_acc: 0.8407\n",
      "Epoch 81/300\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.2631 - acc: 0.8924Epoch 00080: val_acc did not improve\n",
      "253/253 [==============================] - 60s - loss: 0.2628 - acc: 0.8928 - val_loss: 0.3496 - val_acc: 0.8518\n",
      "Epoch 82/300\n",
      "167/253 [==================>...........] - ETA: 19s - loss: 0.2737 - acc: 0.8787"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-234e302787d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_validation_samples\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     callbacks=[checkpoint])\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\\\ft_history.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1095\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1097\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1874\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1875\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1876\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1878\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1620\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1621\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1622\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 2073\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   2074\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "#**import tkinter as tk\n",
    "#from tkinter import filedialog\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "#fix random seed for reproducibility\n",
    "seed = 2017\n",
    "np.random.seed(seed)\n",
    "\n",
    "img_width, img_height = 100, 100\n",
    "\n",
    "#train_data_dir = r'C:\\Users\\yasser\\Desktop\\Caltec_101_Database\\101_ObjectCategories_2C\\train_images'\n",
    "#validation_data_dir = r'C:\\Users\\yasser\\Desktop\\Caltec_101_Database\\101_ObjectCategories_2C\\test_images'\n",
    "#nb_train_samples = 60\n",
    "#nb_validation_samples = 30\n",
    "\n",
    "epochs = 300\n",
    "batch_size = 8\n",
    "lrate = 0.0001\n",
    "decay = 1e-6\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "rmsprop = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(100,100,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "#this is the augmentation configuration we will use for testing:\n",
    "#only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "checkpoint = ModelCheckpoint(fine_tuned_model_path, monitor='val_acc', \n",
    "                                 verbose=1, save_best_only=True, \n",
    "                                 save_weights_only=False, mode='auto')\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint])\n",
    "\n",
    "with open(location+'\\\\ft_history.txt', 'wb') as f:\n",
    "        json.dump(fit.history, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
